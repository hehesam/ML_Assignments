{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bahaar Khalilian, Hesam Mohebi\n",
    "#### Implementation of other models for comparison with KRLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "training_x_path = \"trainingx.csv\"\n",
    "training_y_path = \"trainingy.csv\"\n",
    "\n",
    "X = pd.read_csv(training_x_path, header=None)\n",
    "y = pd.read_csv(training_y_path, header=None).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest tree for multi-class classfication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moheb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Last Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.67      0.06      0.11        35\n",
      "           5       0.70      0.71      0.70       345\n",
      "           6       0.61      0.77      0.68       454\n",
      "           7       0.62      0.40      0.49       169\n",
      "           8       1.00      0.39      0.56        31\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.65      1040\n",
      "   macro avg       0.52      0.33      0.36      1040\n",
      "weighted avg       0.65      0.65      0.63      1040\n",
      "\n",
      "Average accuracy across all folds: 0.6731\n",
      "MSE for training set: 0.0000, MSE for validation set: 0.4616\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error\n",
    "\n",
    "# Initialize lists to store accuracy, confusion matrices, and classification reports for each fold\n",
    "accuracy_scores = []\n",
    "conf_matrices = []\n",
    "class_reports = []\n",
    "\n",
    "for train_idx, val_idx in cv.split(X, y):\n",
    "    # Split data into train and validation sets for the fold\n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Scale the data\n",
    "    X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_val_scaled = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Train the classifier on the fold\n",
    "    rf_classifier.fit(X_train_scaled, y_train_fold)\n",
    "    \n",
    "    # Predict on train and validation sets\n",
    "    y_train_pred = rf_classifier.predict(X_train_scaled)\n",
    "    y_val_pred = rf_classifier.predict(X_val_scaled)\n",
    "    \n",
    "    # Compute MSE for the fold\n",
    "    mse_train.append(mean_squared_error(y_train_fold, y_train_pred))\n",
    "    mse_val.append(mean_squared_error(y_val_fold, y_val_pred))\n",
    "    \n",
    "    # Append accuracy, confusion matrix, and classification report\n",
    "    accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    conf_matrices.append(confusion_matrix(y_val_fold, y_val_pred))\n",
    "    class_reports.append(classification_report(\n",
    "        y_val_fold, y_val_pred, output_dict=True, zero_division=0  # Suppress warning for undefined metrics\n",
    "    ))\n",
    "\n",
    "# Calculate mean MSE for train and validation\n",
    "mean_mse_train = np.mean(mse_train)\n",
    "mean_mse_val = np.mean(mse_val)\n",
    "\n",
    "# Average accuracy across all folds\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "# Display metrics for the last fold as an example\n",
    "conf_matrix_last_fold = pd.DataFrame(conf_matrices[-1])\n",
    "class_report_last_fold = pd.DataFrame(class_reports[-1])\n",
    "\n",
    "print(\"\\nClassification Report (Last Fold):\")\n",
    "print(classification_report(y.iloc[val_idx], y_val_pred, zero_division=0))  # Suppress warning for undefined metrics\n",
    "print(f\"Average accuracy across all folds: {avg_accuracy:.4f}\")\n",
    "print(f\"MSE for training set: {mean_mse_train:.4f}, MSE for validation set: {mean_mse_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### The average accuracy accross all the folds is 67% which indicates the model performs moderately well on the data set. Yet class imbalance is profound especialy in 3 and 9 classes. \n",
    "#### The MSE on training set is 0 indicating the model has fully learn the features of training (potential overfitting), The validation MSE is 46% which suggests the model strugles with generalization speciall for underrepresented classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moheb\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Last Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.14      0.57      0.23        35\n",
      "           5       0.59      0.56      0.58       345\n",
      "           6       0.58      0.27      0.37       454\n",
      "           7       0.36      0.42      0.39       169\n",
      "           8       0.12      0.61      0.21        31\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.41      1040\n",
      "   macro avg       0.26      0.35      0.25      1040\n",
      "weighted avg       0.52      0.41      0.43      1040\n",
      "\n",
      "Average accuracy across all folds: 0.4232\n",
      "MSE for training set: 1.1009, MSE for validation set: 1.2096\n"
     ]
    }
   ],
   "source": [
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize SVM classifier\n",
    "svm_classifier = SVC(class_weight='balanced', probability=True, random_state=42)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "mse_train = []\n",
    "mse_val = []\n",
    "accuracy_scores = []\n",
    "conf_matrices = []\n",
    "class_reports = []\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for train_idx, val_idx in cv.split(X, y):\n",
    "    # Split data into train and validation sets for the fold\n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Scale the data\n",
    "    X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_val_scaled = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Train the SVM classifier on the fold\n",
    "    svm_classifier.fit(X_train_scaled, y_train_fold)\n",
    "    \n",
    "    # Predict on train and validation sets\n",
    "    y_train_pred = svm_classifier.predict(X_train_scaled)\n",
    "    y_val_pred = svm_classifier.predict(X_val_scaled)\n",
    "    \n",
    "    # Compute MSE for the fold\n",
    "    mse_train.append(mean_squared_error(y_train_fold, y_train_pred))\n",
    "    mse_val.append(mean_squared_error(y_val_fold, y_val_pred))\n",
    "    \n",
    "    # Append accuracy, confusion matrix, and classification report\n",
    "    accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    conf_matrices.append(confusion_matrix(y_val_fold, y_val_pred))\n",
    "    class_reports.append(classification_report(\n",
    "        y_val_fold, y_val_pred, output_dict=True, zero_division=0  # Suppress warning for undefined metrics\n",
    "    ))\n",
    "\n",
    "# Calculate mean MSE for train and validation\n",
    "mean_mse_train = np.mean(mse_train)\n",
    "mean_mse_val = np.mean(mse_val)\n",
    "\n",
    "# Average accuracy across all folds\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "# Display metrics for the last fold as an example\n",
    "conf_matrix_last_fold = pd.DataFrame(conf_matrices[-1])\n",
    "class_report_last_fold = pd.DataFrame(class_reports[-1])\n",
    "\n",
    "print(\"\\nClassification Report (Last Fold):\")\n",
    "print(classification_report(y.iloc[val_idx], y_val_pred, zero_division=0))  # Suppress warning for undefined metrics\n",
    "print(f\"Average accuracy across all folds: {avg_accuracy:.4f}\")\n",
    "print(f\"MSE for training set: {mean_mse_train:.4f}, MSE for validation set: {mean_mse_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The average accuracy across all folds is 42.32%, which is significantly lower than the Random Forest model's performance (67.31%). This indicates that the SVM struggles with this dataset, potentially due to class imbalances or insufficient feature representation.\n",
    "##### The training MSE is 1.1009, which reflects significant prediction errors on the training data. The validation MSE is 1.2096, showing that the model has difficulty generalizing to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-layer-perseptron classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Last Fold):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.17      0.20      0.18         5\n",
      "           4       0.18      0.14      0.16        35\n",
      "           5       0.63      0.63      0.63       345\n",
      "           6       0.62      0.61      0.62       454\n",
      "           7       0.50      0.55      0.53       169\n",
      "           8       0.39      0.35      0.37        31\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.58      1040\n",
      "   macro avg       0.36      0.36      0.35      1040\n",
      "weighted avg       0.58      0.58      0.58      1040\n",
      "\n",
      "Average accuracy across all folds: 0.5974\n",
      "MSE for training set: 0.0000, MSE for validation set: 0.6999\n"
     ]
    }
   ],
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize MLP (Multi-Layer Perceptron) classifier with a more complex architecture\n",
    "mlp_classifier = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64, 32),  # Three layers with decreasing neurons\n",
    "    activation='relu',\n",
    "    solver='lbfgs',  # Efficient solver for small to medium datasets\n",
    "    max_iter=1000,  # Allow more iterations for convergence\n",
    "    random_state=42,\n",
    "    early_stopping=True,  # Stop training if validation score stops improving\n",
    ")\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "mse_train = []\n",
    "mse_val = []\n",
    "accuracy_scores = []\n",
    "conf_matrices = []\n",
    "class_reports = []\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "for train_idx, val_idx in cv.split(X, y):\n",
    "    # Split data into train and validation sets for the fold\n",
    "    X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "    \n",
    "    # Scale the data\n",
    "    X_train_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_val_scaled = scaler.transform(X_val_fold)\n",
    "    \n",
    "    # Train the MLP classifier on the fold\n",
    "    mlp_classifier.fit(X_train_scaled, y_train_fold)\n",
    "    \n",
    "    # Predict on train and validation sets\n",
    "    y_train_pred = mlp_classifier.predict(X_train_scaled)\n",
    "    y_val_pred = mlp_classifier.predict(X_val_scaled)\n",
    "    \n",
    "    # Compute MSE for the fold\n",
    "    mse_train.append(mean_squared_error(y_train_fold, y_train_pred))\n",
    "    mse_val.append(mean_squared_error(y_val_fold, y_val_pred))\n",
    "    \n",
    "    # Append accuracy, confusion matrix, and classification report\n",
    "    accuracy_scores.append(accuracy_score(y_val_fold, y_val_pred))\n",
    "    conf_matrices.append(confusion_matrix(y_val_fold, y_val_pred))\n",
    "    class_reports.append(classification_report(\n",
    "        y_val_fold, y_val_pred, output_dict=True, zero_division=0  # Suppress undefined metrics\n",
    "    ))\n",
    "\n",
    "# Calculate mean MSE for train and validation\n",
    "mean_mse_train = np.mean(mse_train)\n",
    "mean_mse_val = np.mean(mse_val)\n",
    "\n",
    "# Average accuracy across all folds\n",
    "avg_accuracy = np.mean(accuracy_scores)\n",
    "\n",
    "# Display metrics for the last fold as an example\n",
    "conf_matrix_last_fold = pd.DataFrame(conf_matrices[-1])\n",
    "class_report_last_fold = pd.DataFrame(class_reports[-1])\n",
    "\n",
    "print(\"\\nClassification Report (Last Fold):\")\n",
    "print(classification_report(y.iloc[val_idx], y_val_pred, zero_division=0))  # Suppress undefined metrics\n",
    "print(f\"Average accuracy across all folds: {avg_accuracy:.4f}\")\n",
    "print(f\"MSE for training set: {mean_mse_train:.4f}, MSE for validation set: {mean_mse_val:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The average accuracy across all folds is 59.74%, which is an improvement over the SVM model (42.32%) but still below the performance of the Random Forest model (67.31%). This suggests that the MLP captures some patterns but struggles to generalize as effectively as Random Forest.\n",
    "#### The training MSE is 0.0000, indicating overfitting, as the model fits the training data perfectly. The validation MSE is 0.6999, which reflects the model's inability to generalize well, particularly on the minority classes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
